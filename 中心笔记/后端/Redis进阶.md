## 缓存更新策略

![[Pasted image 20250715134904.png]]

#### 主动更新

**实现方法:**

![[Pasted image 20250715134910.png]]

常用的就是第一种缓存的方式,在数据库数据更新时删除对应的缓存(因为如果是更新缓存的话会有很多无效操作,比如一个数据更新了很多次但是这段时间内并没有人来查询)

**缓存和数据库的操作顺序:**

不论是先删缓存还是先修改数据库,都有一定的问题,需要根据情景进行选择

1. 先删缓存再操作数据库
    

如果缓存删除后数据库的修改较慢,中间的过程可能就有访问去查询对应的数据,此时因为缓存未命中就会去查未更新的数据库,结果把旧数据又刷回缓存了,导致了数据的不一致

2. 先操作数据库再删缓存
    

这样就有可能在用户查询的过程中,缓存先是失效的,然后去查询数据库,准备更新缓存的过程中数据库又发生了修改,但是此时缓存还没有加载所以没有删除东西,但是之后用户的查询刷新的缓存是旧数据导致数据不一致

第二种情况因为缓存修改的操作一般比数据库的操作快所以发生的可能性比较小,所以一般采用第二种方案,使用超时剔除(为缓存设置过期时间)来兜底

## 缓存问题

#### 缓存穿透

缓存穿透是指客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。

解决方法:

1. 缓存空对象: 未查询到的数据缓存一个空对象,并设置过期时间
    
2. 布隆过滤:
    

![[Pasted image 20250715134919.png]]

在缓存前加一个布隆过滤器,布隆过滤器的实现类似卡表,他会将数据库中的数据计算哈希然后在过滤器中用二进制位映射,但是这个不存在是一定不存在,但是存在是可能存在,即有一定概率

此外还可以通过一些主动手段防止内存穿透,如增强id复杂度,让请求者难以猜测那个id是空数据,或者做好数据的基础格式校验,防止一些不可能的查询,还有用户权限和热点限流

#### 缓存雪崩

缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。

**解决方案:**

1. 给不同的Key的TTL添加随机值(防止大量key同时失效)
    
2. 利用Redis集群提高服务的可用性(防止redis宕机)
    
3. 给缓存业务添加降级限流策略(保护数据库)
    
4. 给业务添加多级缓存
    

#### 缓存击穿

缓存击穿问题也叫热点Key问题，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。

常见的解决方案有两种:

1. 互斥锁: 在查询缓存未命中查询数据库之间加锁,如果获取锁则去更新缓存,否则就等待重试查询缓存
    
2. 逻辑过期: 也需要在更新缓存前加互斥锁,不设置过期时间,而是在字段中额外添加一个逻辑过期时间,查询时发现逻辑过期则获取锁并异步更新缓存,此时原来的请求会返回旧数据,之后再缓存更新完之前的请求也都会获取锁失败,但是此时会直接返回旧数据而不是阻塞.
    
![[Pasted image 20250715134933.png]]
![[Pasted image 20250715134940.png]]
![[Pasted image 20250715134945.png]]
**互斥锁****的实现:**

![[Pasted image 20250715135007.png]]

Redis自带一个setnx方法(springredis中为setIfAbsent()),只有键不存在时才可以写入,否则返回0,这个方法可以模拟一把互斥锁,只有第一个执行的线程才能执行成功返回1,要释放锁就得把这个键删除掉,同时为了防止某一把锁出问题一直没有被释放,一般在设置时会加上过期时间兜底.
尝试获取锁:
![[Pasted image 20250715135015.png]]
释放锁:
![[Pasted image 20250715135024.png]]

#### 逻辑过期

![[Pasted image 20250715135048.png]]
在缓存中存在的格式
![[Pasted image 20250715135055.png]]
添加缓存
![[Pasted image 20250715135110.png]]

## 唯一主键

数据库主键使用自增策略会导致id太过规律,比如用户可以从两条id中看出这期间数据库增加了多少数据,产生了信息泄露,此外单表数据量是有限的,无法无限增长,如果要分表那么就会出现重复的订单id,这是不应该的,这时候应该使用全局id生成器

全局ID生成器，是一种在分布式系统下用来生成全局唯一ID的工具

**ID的组成部分(每个0都是一个二进制位):**

![[Pasted image 20250715135123.png]]

符号位:1bit，永远为0

时间戳:31bit，以秒为单位，可以使用69年

序列号:32bit，秒内的计数器，支持每秒产生2^32个不同ID

这样在redis中每个前缀存放的数据量就很少了,不会到达自增的上限

#### 实现

1. Redis自增
    

![[Pasted image 20250715135130.png]]

最后是将时间向左位运算留出序列号的空间,再将实际的序列号与结果或一下就可以得到正确的值了

2. 除此之外也可以使用UUID生成,但是那个生成的序列并没有什么特殊意义
    
3. 雪花算法
    

## 分布式锁

#### 实现方式

![[Pasted image 20250715135136.png]]

使用Redis实现时因为锁有着固定的过期时间,如果一个线程出于某些原因持续了很长时间,那么这个锁就会自动删除,此时就会有别的线程可以获取锁,甚至还可能此时原线程执行完毕导致释放了别的线程的锁的问题,为了解决这个问题,我们可以在释放锁时对线程进行判断,在redis中新加一个对于线程的标识,释放锁时判断这个标识是否为当前线程的,否则就不进行任何操作

> 对于判断标识和释放锁的操作,这两条操作需要原子性,我们可以使用Lua脚本实现多条redis的原子性,redis的事务也可以,但是redis的事务可以保证原子性但是无法保证一致性,并且一个事务中的操作其实是在最后一次性执行的,即我们不能先查询再判断,因为他们是同时执行的

```Lua
--获取锁中的线程标示get key
local id = redis.call('get', KEYS[1])
--比较线程标示与锁中的标示是否一致
if(id == ARGV[1])then
    --释放锁 del key
    return redis.call('del', KEYS[1])
end
return 0
```

redistemplate中有execute方法可以执行lua脚本,需要提前定义一个RedisScript对象,他有一个泛型就是返回值类型,调用其中的setLocation()指定脚本的路径

#### Redisson

Redisson是一个在Redis的基础上实现的]ava驻内存数据网格(In-MemoryData Grid)。它不仅提供了一系列的分布式

的Java常用对象，还提供了许多分布式服务，其中就包含了各种分布式锁的实现。

1. 引入依赖
    

```YAML
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.13.6</version>
</dependency>
```

2. 配置Redisson客户端
    

```Java
@Configuration
public class Redisconfig{
    @Bean
    public RedissonClient redissonclient(){
        // 配置类
        Config config = new Config();
        //添加redis地址，这里添加了单点的地址，也可以使用config.useClusterServers()添加集群地址
       config.useSingleServer().setAddress("redis://192.168.150.101:6379").setPassowrd("123321");
        // 创建客户端
        return Redisson.create(config);
    }
}
```

3. 实例
    

```Java
@Resource
private RedissonClient redissonclient;

@Test
void testRedisson()throws InterruptedException {
    // 获取锁(可重入)，指定锁的名称
    RLock lock=redissonclient.getLock("anyLock");
    //尝试获取锁，参数分别是:获取锁的最大等待时间(期间会重试)，锁自动释放时间，时间单位
    boolean isLock = lock.tryLock(1,10，TimeUnit.SECONDS);
    // 判断释放获取成功
    if(isLock){
        try {
            System.out.println("执行业务");
        }finally {
        // 释放锁
        lock.unlock();
        }
    }
}
```

其中可重入锁的默认参数为不重试且超时时间为30s

#### Redisson原理

1. 可重入锁
    

要实现可重入,在redis的字段中除了标识外还需要存储重入的次数,并且每次重入或者释放锁都会重置锁的超时时间,直到重入数为0才真正删除锁,Redisson使用hash结构存储

2. 失败重试
    

Redisson内部会订阅自己等待的那个锁的线程id,而不会一直循环重试,直到到达最大等待时间

3. 超时续约
    

如果没有锁超时释放时间(重试时间为-1),就会启动看门狗机制不断刷新锁的持续时间,(看门狗会执行一个定时任务,每 锁超时时间/3 时间后刷新一次锁的ttl,只有在释放锁的时候才取消这个任务),如果设置了就不启动看门狗机制了

![[Pasted image 20250715135149.png]]

4. 主从一致性
    

主从模式下如果主节点向从节点同步时发生故障,就会导致锁丢失,所以可以让主从节点都平等,即保存一样的数据,每次查询锁时都遍历每个节点获取锁,只有从每个节点那都获取锁才算获取成功,这样就算有一个节点宕机也没有问题,此外还可以给这些节点在配置主从节点,此时就算再发生同步失败,也会因为在这个节点获取锁失败而导致无法获取锁

这种方案也叫做连锁,要实现这种方案,需要为每一个节点注册Client为Bean

```Java
void setUp(){
    RLock lockl = redissonclient.getLock("order");
    RLock lock2 = redissonclient2.getLock("order");
    RLock lock3 = redissonclient3.getLock("order");
    // 创建联锁 multiLock
    lock = redissonclient.getMultiLock(lockl, lock2, lock3);
}
```

这样在尝试获取锁时就会遍历每一个锁尝试上锁,有一个锁获取失败就会释放之前所获取的所有锁

## 消息队列

Redis提供了三种不同的方式来实现消息队列:

- list结构:基于List结构模拟消息队列
    
- Pubsub:基本的点对点消息模型
    
- Stream:比较完善的消息队列模型
    

![[Pasted image 20250715135157.png]]

#### List

reids的list实质是一个双向列表,可以使用blpush和brpop(这两个方法对比单纯的存和取,在没有数据时会阻塞)模拟队列

但是这种方法无法进行消费者确认和失败重试,并且只能单点推送

#### PubSub

Pubsub(发布订阅)是Redis2.0版本引入的消息传递模型。顾名思义，消费者可以订阅一个或多个channel，生产者向对应channel发送消息后，所有订阅者都能收到相关消息。

- SUBSCRIBE channel [channel]:订阅一个或多个频道(订阅都是阻塞式的)
    
- PUBLISH channel msq :向一个频道发送消息,会返回接收到消息的消费者数量
    
- PSUBSCRlBE pattern [pattern]:订阅与pattern格式匹配的所有频道
    

> ?代表一个字符,*代表另个或多个,[]内可以指定特定的字母

但是这种方式不支持消息持久话,发布的数据即使没人消费也会直接丢失不会暂存,相对的同时有多条消息时会在消费者处创建缓存队列,但是这个队列也是存在存储上限的

#### Stream

Stream 是 Redis 5.0 引入的一种新数据类型，可以实现一个功能非常完善的消息队列。

常用方法:

- XADD <队列名称> <消息id(可以写*,代表由redis自动生成,自己写也要遵守"时间戳-递增数字"的格式)> <字段名> <值>...(可以写多个键值对) :发布消息
    

`XADD users * name jack age 21`

- XLEN <队列名> :可以获取队列中的消息个数
    
- 读取消息(消息读取后并不会删除,可以重复读,可以使用$来访问最后一条消息,所以存在消息漏读的风险)
    

![[Pasted image 20250715135206.png]]

> 阻塞时长为0时代表永久阻塞,直到读取到消息为止,如果阻塞时长耗尽未收到消息则返回null

**消费者组:**

消费者组(ConsumerGroup):将多个消费者划分到一个组中,监听同一个队列。具备下列特点:

![[Pasted image 20250715135213.png]]

![[Pasted image 20250715135219.png]]

![[Pasted image 20250715135225.png]]

> 使用0获取一条未确认的消息后这条消息就会从list中剔除,所以下次使用0获取的就是另一条消息了,可以这样处理异常的消息

确认消息处理完成需要消费者自己发送,使用XACK key group ID [ID...]

#### Java集成Stream

![[Pasted image 20250715135231.png]]
![[Pasted image 20250715135238.png]]